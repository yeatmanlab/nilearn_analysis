{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7096f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Functional connectivity on LMB data\n",
    "# import\n",
    "from nilearn import datasets\n",
    "from nilearn import surface\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from nilearn import signal\n",
    "from scipy import stats\n",
    "import nibabel as nib\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import sys\n",
    "#matplotlib.use('agg') # supposed to avoid memory leak - add to .py version of code when not running as notebook\n",
    "#load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf7ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 subjects in inputdir\n",
      "['sub-173', 'sub-1452', 'sub-1215', 'sub-108', 'sub-1210', 'sub-1380', 'sub-1362', 'sub-984', 'sub-230', 'sub-641', 'sub-2130', 'sub-1339', 'sub-1234', 'sub-1395', 'sub-1335', 'sub-107', 'sub-309', 'sub-2158', 'sub-1211', 'sub-1021', 'sub-1444', 'sub-1453', 'sub-1020']\n"
     ]
    }
   ],
   "source": [
    "# Load subject fmri data\n",
    "# This will loop across subjects\n",
    "projectdir = '/scratch/groups/jyeatman/LMB_BIDS/derivatives/fmriprep/'\n",
    "inputdir = projectdir\n",
    "outputdir = '/scratch/groups/jyeatman/LMB_Connectivity/' # We don't want to write into the BIDS folder\n",
    "#subs = glob.glob(datadir + 'sub-*') # this gets the full path\n",
    "subs = [os.path.splitext(os.path.basename(x))[0] for x in glob.glob(projectdir + '/sub-*.html')]\n",
    "print('Found ' + str(len(subs)) + ' subjects in inputdir')\n",
    "print(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936d5044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-1020', 'sub-1021', 'sub-107', 'sub-108', 'sub-1210', 'sub-1211', 'sub-1215', 'sub-1234', 'sub-1335', 'sub-1339', 'sub-1362', 'sub-1380', 'sub-1395', 'sub-1444', 'sub-1452', 'sub-1453', 'sub-173', 'sub-2130', 'sub-2158', 'sub-230', 'sub-309', 'sub-641', 'sub-984']\n"
     ]
    }
   ],
   "source": [
    "subs.sort()\n",
    "print(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8bb140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "exclude_subs = ['sub-1211','sub-1215','sub-108','sub-1453']\n",
    "subs = [sub for sub in subs if not any(removed_sub in sub for removed_sub in exclude_subs)]\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfd1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 19 subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/nilearn/surface/surface.py:671: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray([arr.data for arr in gifti_img.darrays]).T.squeeze()\n"
     ]
    }
   ],
   "source": [
    "# Where to save outputs: \n",
    "surfacedir = outputdir + 'surface/statMaps/'\n",
    "imagedir =  outputdir + 'surface/images/'\n",
    "\n",
    "if not os.path.exists(surfacedir):\n",
    "    os.makedirs(surfacedir)\n",
    "\n",
    "if not os.path.exists(imagedir):\n",
    "    os.makedirs(imagedir)\n",
    "\n",
    "# Paths to surface ROIs from Emily\n",
    "roidir =  '/home/groups/jyeatman/ROI_Atlases/visfAtlas/Emily/'\n",
    "roi_names = ['lh_pOTS_chars.label','lh_mOTS_chars.label','MPM_lh_IOS.label']\n",
    "# the IOS ROI is a character selective ROI from Rosenke 2021, looks like OWFA\n",
    "\n",
    "# Which task\n",
    "task = 'rest' # LMB only have movie, but we call it 'rest' in the BIDS structure\n",
    "hemi = 'left' # right or left\n",
    "seed_hemi = 'left'\n",
    "runs = ['1','2']\n",
    "sessions = ['ses-2']\n",
    "# which correlation to save\n",
    "corr_type = 'fisherz' # options are 'rval', 'fisherz'\n",
    "\n",
    "overwrite = False\n",
    "createFigs = True # create connectivity maps per subject\n",
    "saveFigs = True   # Save png files of connectivity maps\n",
    "saveMaps = False   # Save actual connectivity map as a curv file that can \n",
    "# be loaded to Freeview\n",
    "saveGroup = True\n",
    "\n",
    "# Run on a subset of data for debugging\n",
    "#subs = ['sub-641','sub-1234','sub-984']\n",
    "subs = pd.DataFrame(subs, columns =['participant_id'])\n",
    "subs = subs['participant_id']\n",
    "\n",
    "timepoints = 375;\n",
    "TR = 0.82\n",
    "droptp = [0,1,2,3,4,5]\n",
    "fd_thresh = 0.5\n",
    "fd_vol_thresh = 90 # include only scans with >90% usable volumes\n",
    "\n",
    "# Load fsaverage\n",
    "fsaverage = datasets.fetch_surf_fsaverage('fsaverage')\n",
    "# Load LH surface to get its size\n",
    "white_left = surface.load_surf_data(fsaverage['white_left'])\n",
    "# Load RH surface to get its size\n",
    "white_right = surface.load_surf_data(fsaverage['white_right'])\n",
    "\n",
    "# Load subject list\n",
    "# TBD when there's a dataframe for LMB subjects\n",
    "\n",
    "# parse command-line arguments; to use on Sherlock\n",
    "# start = int(sys.argv[1])\n",
    "# end = int(sys.argv[2])\n",
    "# subs = subs[start:end]\n",
    "\n",
    "sub_count = len(subs)\n",
    "print('Running on ' + str(sub_count) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aa5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE ATLAS ROIs?\n",
    "# we want to save these files in a separate folder\n",
    "atlas = False\n",
    "\n",
    "if atlas == True:\n",
    "    roi_names = [b'S_front_inf',b'S_intrapariet_and_P_trans']\n",
    "    roidir = 'Atlas'\n",
    "    surfacedir = outputdir + 'surface/Atlas/statMaps/'\n",
    "    imagedir =  outputdir + 'surface/Atlas/images/'\n",
    "    if not os.path.exists(surfacedir):\n",
    "        os.makedirs(surfacedir)\n",
    "    if not os.path.exists(imagedir):\n",
    "        os.makedirs(imagedir)\n",
    "    destrieux_atlas = datasets.fetch_atlas_surf_destrieux()\n",
    "    parcellation = destrieux_atlas['map_' + hemi]\n",
    "    labels = destrieux_atlas['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8242a0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "['lh_pOTS_chars.label', 'lh_mOTS_chars.label', 'MPM_lh_IOS.label']\n",
      "/scratch/groups/jyeatman/LMB_Connectivity/surface/statMaps/\n",
      "/scratch/groups/jyeatman/LMB_Connectivity/surface/images/\n"
     ]
    }
   ],
   "source": [
    "print(len(subs))\n",
    "print(roi_names)\n",
    "print(surfacedir)\n",
    "print(imagedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f699216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing ROI /home/groups/jyeatman/ROI_Atlases/visfAtlas/Emily/lh_pOTS_chars.label\n",
      "sub-1020_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 0\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1021_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 1\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-107_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 2\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1210_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 3\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1234_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 4\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1335_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 5\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1339_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 6\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1362_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 7\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1380_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 8\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "Cant find sub-1395_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "sub-1444_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 10\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-1452_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 11\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-173_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 12\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-2130_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 13\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-2158_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 14\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-230_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 15\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-309_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 16\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-641_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 17\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "sub-984_ses-2_task-rest_lh_pOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 18\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "Calculating mean connectivity for lh_pOTS_chars.label\n",
      "Analyzing ROI /home/groups/jyeatman/ROI_Atlases/visfAtlas/Emily/lh_mOTS_chars.label\n",
      "sub-1020_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 0\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1021_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 1\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-107_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 2\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1210_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 3\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1234_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 4\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1335_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 5\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1339_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 6\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1362_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 7\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "sub-1380_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 8\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Cant find sub-1395_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "sub-1444_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh.npy exists, \n",
      "skipping sub # 10\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 11 sub-1452_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1452\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1452_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 12 sub-173_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-173\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-173_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 13 sub-2130_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-2130\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-2130_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 14 sub-2158_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-2158\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-2158_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 15 sub-230_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-230\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-230_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 16 sub-309_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-309\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-309_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 17 sub-641_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-641\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-641_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Loading sub # 18 sub-984_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-984\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-984_ses-2_task-rest_lh_mOTS_chars.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Calculating mean connectivity for lh_mOTS_chars.label\n",
      "Analyzing ROI /home/groups/jyeatman/ROI_Atlases/visfAtlas/Emily/MPM_lh_IOS.label\n",
      "Loading sub # 0 sub-1020_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1020\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1020_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 1 sub-1021_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1021\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1021_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 2 sub-107_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-107\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-107_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 3 sub-1210_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1210\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1210_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 4 sub-1234_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1234\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1234_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 5 sub-1335_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1335\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1335_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 6 sub-1339_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1339\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1339_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 7 sub-1362_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1362\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1362_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 8 sub-1380_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1380\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1380_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Cant find sub-1395_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Loading sub # 10 sub-1444_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Cant find sub-1444_ses-2_task-rest_run-2_space-fsaverage_hemi-L_bold.func.gii\n",
      "Analysing a single run!\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 369)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Cant find /scratch/groups/jyeatman/LMB_BIDS/derivatives/fmriprep/sub-1444/ses-2/func/sub-1444_ses-2_task-rest_run-2_desc-confounds_timeseries.tsv\n",
      "Analysing a single run!\n",
      "Number of confounds after dropping: (369, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1444\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1444_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 11 sub-1452_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-1452\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-1452_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 12 sub-173_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-173\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-173_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 13 sub-2130_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-2130\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-2130_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 14 sub-2158_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-2158\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-2158_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 15 sub-230_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-230\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-230_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 16 sub-309_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-309\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-309_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 17 sub-641_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-641\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-641_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Loading sub # 18 sub-984_ses-2_task-rest_run-1_space-fsaverage_hemi-L_bold.func.gii\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "Original Data Vertices by Timepoints\n",
      "(163842, 375)\n",
      "dropping volumes: [0, 1, 2, 3, 4, 5, 375, 376, 377, 378, 379, 380]\n",
      "After dropping initial 6 Timepoints, Vertices by Timepoints\n",
      "(163842, 738)\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds: 14\n",
      "Number of timepoints: 369\n",
      "Number of confounds after dropping: (738, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/jyeatman/software/mayay/anaconda3/envs/FC/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing stat_map sub-984\n",
      "Saving /scratch/groups/jyeatman/LMB_Connectivity/surface/images/sub-984_ses-2_task-rest_MPM_lh_IOS.label_fisherz_lh_lateral.png\n",
      "\n",
      "\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n",
      "Calculating mean connectivity for MPM_lh_IOS.label\n"
     ]
    }
   ],
   "source": [
    "# Try loading a gii surface file that was previously saved\n",
    "# When the seed ROI is not in the same hemisphere that we want to analyse, we actually need to load two surfaces:\n",
    "# one to calculate the seed_timeseries of the source ROI, and another to extract all timeseries of all \n",
    "# vertices in the other hemisphere\n",
    "\n",
    "for rr in range(len(roi_names)):\n",
    "    # Allocate empty array for group data - N subjects * n vertices\n",
    "    # We create a blank group_map here to avoid data bleeding from ROI to ROI in case there are missing values \n",
    "    if hemi == 'left':\n",
    "        group_map = np.zeros(shape = (len(subs),white_left[0].shape[0]))\n",
    "    elif hemi == 'right':\n",
    "        group_map = np.zeros(shape = (len(subs),white_right[0].shape[0]))\n",
    "\n",
    "    # Load ROI\n",
    "    if atlas == False:\n",
    "        cur_roi = surface.load_surf_data(roidir + roi_names[rr])\n",
    "        cur_roi = cur_roi.astype(int) \n",
    "        print('Analyzing ROI ' + roidir + roi_names[rr])\n",
    "    else:\n",
    "        cur_roi = np.where(parcellation == labels.index(roi_names[rr]))[0]\n",
    "        cur_roi = cur_roi.astype(int)\n",
    "        # roi_names for the Atlas are bytes, not strings\n",
    "        # (begin with 'b' --> need to be decoded inco UTF8)\n",
    "        roi_names[rr] = roi_names[rr].decode()\n",
    "        print('Analyzing ROI ' + roidir + ' ' + roi_names[rr])\n",
    "        \n",
    "        \n",
    "    # Loop over subjects and compute connectivity for that ROI\n",
    "    for ses in sessions:\n",
    "        for ii in range(len(subs)):  \n",
    "            output_subfilename = subs.iloc[ii] +'_'+ ses + '_task-' + task + '_' + roi_names[rr] + '_' + corr_type + '_' + hemi[0] + 'h.npy'\n",
    "            # if this subject's map had already been calculated, load it instead of recalculating\n",
    "            if os.path.exists(surfacedir + output_subfilename):\n",
    "                print(output_subfilename +' exists, \\nskipping sub # ' + str(ii))\n",
    "                stat_map = np.load(surfacedir + output_subfilename)\n",
    "                group_map[ii,:] = stat_map \n",
    "\n",
    "            else:\n",
    "                # Load data for full hemisphere\n",
    "                sub_dir = inputdir + subs.iloc[ii] + '/' + ses + '/func/' # maybe we won't use sub_dir for anything? \n",
    "                func_file_1 = subs[ii] + '_' + ses + '_task-rest_run-1_space-fsaverage_hemi-'+ hemi[0].upper()+ '_bold.func.gii'\n",
    "                func_file_2 = str.replace(func_file_1,'run-1','run-2')\n",
    "                if not exists(sub_dir + func_file_1):\n",
    "                    print('Cant find ' + func_file_1)\n",
    "                    continue\n",
    "                else:\n",
    "                    print('Loading sub # ' + str(ii) + ' ' + func_file_1)\n",
    "                    run_data_1 = surface.load_surf_data(sub_dir + func_file_1)\n",
    "                    # saving as gii and loading the surface seems to transpose the data\n",
    "                    # we want our data to be vertices * timepoints\n",
    "                    if run_data_1.shape[0] < run_data_1.shape[1]:\n",
    "                        run_data_1 = np.transpose(run_data_1)\n",
    "                    print('Original Data Vertices by Timepoints')\n",
    "                    print(run_data_1.shape) \n",
    "                    if not exists(sub_dir + func_file_2):\n",
    "                        print('Cant find ' + func_file_2 + '\\nAnalysing a single run!')\n",
    "                        run_data = run_data_1\n",
    "                        dropall = droptp\n",
    "                    else:\n",
    "                        run_data_2 = surface.load_surf_data(sub_dir + func_file_2)\n",
    "                        if run_data_2.shape[0] < run_data_2.shape[1]:\n",
    "                            run_data_2 = np.transpose(run_data_2)\n",
    "                        print('Original Data Vertices by Timepoints')\n",
    "                        print(run_data_2.shape) \n",
    "                        run_data = np.concatenate((run_data_1,run_data_2),axis =1)\n",
    "                   # we want to drop the same volumes from the second run as well\n",
    "                        droptp2 = [x + int(run_data.shape[1]/2) for x in droptp]\n",
    "                        dropall = droptp + droptp2\n",
    "                        print('dropping volumes: ' + str(dropall))\n",
    "\n",
    "                    run_data = np.delete(run_data,dropall,axis=1)\n",
    "                    print('After dropping initial 6 Timepoints, Vertices by Timepoints')\n",
    "                    print(run_data.shape) \n",
    "                    # TBD - implement scrubbing\n",
    "\n",
    "                # Load data for seed ROI if different from target hemisphere    \n",
    "                if seed_hemi == hemi:\n",
    "                    run_data_seed = run_data.copy()\n",
    "                else:\n",
    "                    func_file_seed_1 = str.replace(func_file_1,hemi[0].upper(),seed_hemi[0].upper())\n",
    "                    func_file_seed_2 = str.replace(func_file_seed_1,'run-1','run-2')\n",
    "                    print('Loading sub # ' + str(ii) + ' ' + func_file_seed_1)\n",
    "                    if not exists(sub_dir + func_file_seed_1):\n",
    "                        print('Cant find ' + func_file_seed_1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        print('Loading sub # ' + str(ii) + ' ' + func_file_seed_1)\n",
    "                        run_data_seed_1 = surface.load_surf_data(sub_dir + func_file_seed_1)\n",
    "                        # saving as gii and loading the surface seems to transpose the data\n",
    "                        # we want our data to be vertices * timepoints\n",
    "                        if run_data_seed_1.shape[0] < run_data_seed_1.shape[1]:\n",
    "                            run_data_seed_1 = np.transpose(run_data_seed_1)\n",
    "                        print('Original Data Vertices by Timepoints')\n",
    "                        print(run_data_seed_1.shape) \n",
    "                        if not exists(sub_dir + func_file_seed_2):\n",
    "                            print('Cant find ' + func_file_seed_2 + '\\nAnalysing a single run!')\n",
    "                            run_data = run_data_seed_1\n",
    "                            dropall = droptp\n",
    "                        else:\n",
    "                            run_data_seed_2 = surface.load_surf_data(sub_dir + func_file_seed_2)\n",
    "                            if run_data_seed_2.shape[0] < run_data_seed_2.shape[1]:\n",
    "                                run_data_seed_2 = np.transpose(run_data_seed_2)\n",
    "                            print('Original Data Vertices by Timepoints')\n",
    "                            print(run_data_seed_2.shape) \n",
    "                            run_data_seed = np.concatenate((run_data_seed_1,run_data_seed_2),axis =1)\n",
    "                       # we want to drop the same volumes from the second run as well\n",
    "                            droptp2 = [x + int(run_data.shape[1]/2) for x in droptp]\n",
    "                            dropall = droptp + droptp2\n",
    "                            print('dropping volumes: ' + str(dropall))\n",
    "\n",
    "                        run_data_seed = np.delete(run_data_seed,dropall,axis=1)\n",
    "                        print('After dropping initial 6 Timepoints, Vertices by Timepoints')\n",
    "                        print(run_data_seed.shape) \n",
    "                        # TBD - implement scrubbing\n",
    " \n",
    "                 # Loading confounds\n",
    "                all_con = None\n",
    "                for run in runs:\n",
    "                    conf_file = subs[ii] + '_' + ses + '_task-rest_run-' + run + '_desc-confounds_timeseries.tsv'\n",
    "                    if not exists(sub_dir + conf_file):\n",
    "                        print('Cant find ' + sub_dir + conf_file + '\\nAnalysing a single run!')\n",
    "                        continue\n",
    "                    cur_con_all = pd.read_csv(sub_dir + conf_file, sep = '\\t')\n",
    "                    cur_con = cur_con_all[['csf', 'white_matter','trans_x', 'trans_x_derivative1', 'trans_y','trans_y_derivative1','trans_z', \n",
    "                             'trans_z_derivative1', 'rot_x', 'rot_x_derivative1','rot_y','rot_y_derivative1', \n",
    "                             'rot_z', 'rot_z_derivative1']]\n",
    "                       # TBD - create external function that takes a list of confound\n",
    "                    cur_con = cur_con.drop(droptp)\n",
    "                    print('Number of confounds: ' + str(cur_con.shape[1]))\n",
    "                    print('Number of timepoints: ' + str(cur_con.shape[0]))\n",
    "                    if all_con is None:\n",
    "                        all_con = cur_con\n",
    "                    else:\n",
    "                        all_con = np.concatenate((all_con,cur_con), axis=0)\n",
    "                print('Number of confounds after dropping: ' + str(all_con.shape))\n",
    "                if all_con.shape[0] != run_data.shape[1]:\n",
    "                    print('confound file mismatch with data file, skipping subject\\n')\n",
    "                    continue\n",
    "                \n",
    "                # Clean the data\n",
    "                run_data = np.transpose(signal.clean(signals = np.transpose(run_data), filter=None, detrend=True, standardize='zscore',confounds = all_con))\n",
    "                run_data_seed = np.transpose(signal.clean(signals = np.transpose(run_data_seed), filter=None, detrend=True, standardize='zscore',confounds = all_con))\n",
    "                # Up to here - this part can be done once for each subject and saved somewhere where we can load it\n",
    "                # we can save a cleaned version of the data and load that instead of cleaning everytime we run on a new ROI\n",
    "                # with the current code we have to clean the signal over and over again everytime we run the correlation for different\n",
    "                # ROIs \n",
    "                \n",
    "                # Compute the mean time series for the ROI\n",
    "                seed_timeseries = np.nanmean(run_data_seed[cur_roi], axis=0)\n",
    "           \n",
    "                # Compute correlations between the seed timeseries and each vertex\n",
    "                stat_map = np.zeros(run_data.shape[0])\n",
    "                for i in range(run_data.shape[0]): # this loops through the vertices\n",
    "                    stat_map[i] = stats.pearsonr(seed_timeseries, run_data[i])[0]\n",
    "\n",
    "                print('computing stat_map ' + subs.iloc[ii])\n",
    "                if corr_type == 'fisherz':\n",
    "                # Fisher transform the map\n",
    "                    stat_map = np.arctanh(stat_map)\n",
    "\n",
    "                # Save as a gifti that could be loaded into freeview\n",
    "                if saveMaps:\n",
    "                    targetFile = surfacedir + subs.iloc[ii] + '_task-' + task + '_' + roi_names[rr] + '_' + corr_type + '_'+hemi[0]+'h.curv'\n",
    "                    if not os.path.exists(targetFile):\n",
    "                        nib.freesurfer.io.write_morph_data(targetFile,stat_map)\n",
    "\n",
    "                # Add the stat map to the group stat map\n",
    "                group_map[ii,:] = stat_map \n",
    "\n",
    "                # Save individual correlation maps - this way we can later use a csv with \n",
    "                # a list of subjects and create a group npy from selected subjects\n",
    "                np.save(surfacedir + output_subfilename,stat_map)\n",
    "\n",
    "                # Plot the seed-based connectivity\n",
    "                figTitle = subs.iloc[ii] + ' ' + roi_names[rr]\n",
    "\n",
    "                if createFigs:\n",
    "                    if saveFigs:\n",
    "                        output_filel = imagedir+os.path.splitext(output_subfilename)[0] + '_lateral.png'\n",
    "                        output_filev = imagedir+os.path.splitext(output_subfilename)[0] + '_ventral.png'\n",
    "                        print('Saving ' + output_filel)\n",
    "                    else: \n",
    "                        output_filel = None\n",
    "                        output_filev = None\n",
    "\n",
    "                    plotting.plot_surf_stat_map(fsaverage['white_' + hemi], stat_map=stat_map,\n",
    "                    hemi=hemi, threshold = .3, vmax=0.7, view='lateral', colorbar=True,\n",
    "                    bg_map=fsaverage['curv_'+ hemi], title=figTitle, output_file = output_filel)\n",
    "                    print()\n",
    "                    \n",
    "                    plotting.plot_surf_stat_map(fsaverage['white_' + hemi], stat_map=stat_map,\n",
    "                    hemi=hemi, threshold = .3, vmax=0.7, view='ventral', colorbar=True,\n",
    "                    bg_map=fsaverage['curv_' + hemi], title=figTitle, output_file = output_filev)\n",
    "                    print()\n",
    "\n",
    "        # outside the subject loop, save map of mean connectivity across the entire sample\n",
    "        print('Calculating mean connectivity for ' + roi_names[rr])\n",
    "        group_mean = np.mean(group_map, axis = 0)\n",
    "\n",
    "        # Save map of group mean\n",
    "        output_groupfilename = surfacedir + 'GroupMap_task-' + task + '_' + roi_names[rr] + '_N' + str(len(subs)) + '_' + corr_type + '_' + hemi[0]+'h'\n",
    "        if saveFigs:\n",
    "            output_file = output_groupfilename+ '_lateral.png'\n",
    "            output_file_v = str.replace(output_file,'lateral','ventral')\n",
    "        else:\n",
    "            output_file = None\n",
    "            output_file_v = None\n",
    "\n",
    "        plotting.plot_surf_stat_map(fsaverage['white_' + hemi], stat_map=group_mean,\n",
    "        hemi=hemi, threshold = .25, vmax=0.7, view='lateral', colorbar=True,\n",
    "        bg_map=fsaverage['curv_' + hemi],title='Group map N=' + str(len(subs)), output_file = output_file)\n",
    "\n",
    "        plotting.plot_surf_stat_map(fsaverage['white_' + hemi], stat_map=group_mean,\n",
    "        hemi=hemi, threshold = .25, vmax=0.7, view='ventral', colorbar=True,\n",
    "        bg_map=fsaverage['curv_' + hemi],title='Group map N=' + str(len(subs)), output_file = output_file_v)\n",
    "\n",
    "        if saveGroup:\n",
    "            nib.freesurfer.io.write_morph_data(output_groupfilename+ '.curv',group_mean)        \n",
    "            #save also as numpy array\n",
    "            np.save(output_groupfilename,group_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f827d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02297087  0.43743939 -0.09172817 ...  0.34100834  0.32465085\n",
      "  0.19751657]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f11c2ef4f40>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check:\n",
    "# Test assignment of subject map to group map\n",
    "test_ind  = 1\n",
    "roi_ind = 1\n",
    "output_subfilename = surfacedir + subs.iloc[test_ind] + '_task-' + task + '_' + roi_names[roi_ind] + corr_type + '_'+hemi[0]+'h.npy'\n",
    "test_sub = np.load(output_subfilename)\n",
    "print(test_sub)\n",
    "\n",
    "output_groupfilename = surfacedir + 'GroupMap_task-' + task + '_' + roi_names[roi_ind] + '_N' + str(sub_count) + '_' + corr_type + '_'+hemi[0]+'h.npy'\n",
    "test_group = np.load(output_groupfilename)\n",
    "test_group[test_ind]\n",
    "plt.scatter(test_sub,test_group[test_ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FC",
   "language": "python",
   "name": "fc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
